{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport nilearn as nl\nimport nibabel as nib\nimport nilearn.plotting as nlplt\nfrom skimage import data\nfrom skimage.util import montage \nimport skimage.transform as skTrans\nfrom skimage.transform import rotate\nfrom skimage.transform import resize\nimport os\nimport cv2\nfrom PIL import Image, ImageOps  \nfrom tifffile import imsave\nimport glob\nimport PIL\nimport shutil\n!pip install git+https://github.com/miykael/gif_your_nifti \nimport gif_your_nifti.core as gif2nif\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport keras\nimport keras.backend as K\nfrom keras.callbacks import CSVLogger\nimport tensorflow as tf\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\nfrom tensorflow.keras.layers.experimental import preprocessing\n# tf.keras.optimizers.Adam(learning_rate)\n\nnp.set_printoptions(precision=3, suppress=True)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-10T06:22:04.251285Z","iopub.execute_input":"2022-09-10T06:22:04.251658Z","iopub.status.idle":"2022-09-10T06:22:21.375560Z","shell.execute_reply.started":"2022-09-10T06:22:04.251622Z","shell.execute_reply":"2022-09-10T06:22:21.374298Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"# DEFINE seg-areas  \nSEGMENT_CLASSES = {\n    0 : 'NOT tumor',\n    1 : 'NECROTIC/CORE', \n    2 : 'EDEMA',\n    3 : 'ENHANCING' \n}\n\nVOLUME_SLICES = 100 \nVOLUME_START_AT = 22 ","metadata":{"execution":{"iopub.status.busy":"2022-09-10T06:20:04.015431Z","iopub.execute_input":"2022-09-10T06:20:04.015789Z","iopub.status.idle":"2022-09-10T06:20:04.024213Z","shell.execute_reply.started":"2022-09-10T06:20:04.015720Z","shell.execute_reply":"2022-09-10T06:20:04.023096Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"TRAIN_DATASET_PATH = '../input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/'\nVALIDATION_DATASET_PATH = '../input/brats20-dataset-training-validation/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData'\n\ntest_image_flair=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_flair.nii').get_fdata()\ntest_image_t1=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_t1.nii').get_fdata()\ntest_image_t1ce=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_t1ce.nii').get_fdata()\ntest_image_t2=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_t2.nii').get_fdata()\ntest_mask=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_seg.nii').get_fdata()\n\n\nfig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5, figsize = (20, 10))\nslice_w = 25\nax1.imshow(test_image_flair[:,:,test_image_flair.shape[0]//2-slice_w], cmap = 'gray')\nax1.set_title('Image flair')\nax2.imshow(test_image_t1[:,:,test_image_t1.shape[0]//2-slice_w], cmap = 'gray')\nax2.set_title('Image t1')\nax3.imshow(test_image_t1ce[:,:,test_image_t1ce.shape[0]//2-slice_w], cmap = 'gray')\nax3.set_title('Image t1ce')\nax4.imshow(test_image_t2[:,:,test_image_t2.shape[0]//2-slice_w], cmap = 'gray')\nax4.set_title('Image t2')\nax5.imshow(test_mask[:,:,test_mask.shape[0]//2-slice_w])\nax5.set_title('Mask')\n","metadata":{"execution":{"iopub.status.busy":"2022-09-10T06:20:04.027210Z","iopub.execute_input":"2022-09-10T06:20:04.027824Z","iopub.status.idle":"2022-09-10T06:20:05.027067Z","shell.execute_reply.started":"2022-09-10T06:20:04.027781Z","shell.execute_reply":"2022-09-10T06:20:05.026051Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"# Skip 50:-50 slices since there is not much to see\nfig, ax1 = plt.subplots(1, 1, figsize = (15,15))\nax1.imshow(rotate(montage(test_image_t1[50:-50,:,:]), 90, resize=True), cmap ='gray')","metadata":{"execution":{"iopub.status.busy":"2022-09-10T06:20:05.029483Z","iopub.execute_input":"2022-09-10T06:20:05.030104Z","iopub.status.idle":"2022-09-10T06:20:06.478992Z","shell.execute_reply.started":"2022-09-10T06:20:05.030061Z","shell.execute_reply":"2022-09-10T06:20:06.478068Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"niimg = nl.image.load_img(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_flair.nii')\nnimask = nl.image.load_img(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_seg.nii')\nfig, axes = plt.subplots(nrows=4, figsize=(30, 40))\n\nnlplt.plot_anat(niimg,\n                title='BraTS20_Training_001_flair.nii plot_anat',\n                axes=axes[0])\nnlplt.plot_epi(niimg,\n               title='BraTS20_Training_001_flair.nii plot_epi',\n               axes=axes[1])\nnlplt.plot_img(niimg,\n               title='BraTS20_Training_001_flair.nii plot_img',\n               axes=axes[2])\nnlplt.plot_roi(nimask, \n               title='BraTS20_Training_001_flair.nii with mask plot_roi',\n               bg_img=niimg, \n               axes=axes[3], cmap='Paired')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-10T06:20:06.480841Z","iopub.execute_input":"2022-09-10T06:20:06.481445Z","iopub.status.idle":"2022-09-10T06:20:17.732392Z","shell.execute_reply.started":"2022-09-10T06:20:06.481405Z","shell.execute_reply":"2022-09-10T06:20:17.731474Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"def dice_coef(y_true, y_pred, smooth=1.0):\n    class_num = 4\n    for i in range(class_num):\n        y_true_f = K.flatten(y_true[:,:,:,i])\n        y_pred_f = K.flatten(y_pred[:,:,:,i])\n        intersection = K.sum(y_true_f * y_pred_f)\n        loss = ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n        if i == 0:\n            total_loss = loss\n        else:\n            total_loss = total_loss + loss\n    total_loss = total_loss / class_num\n    return total_loss\n\ndef dice_coef_necrotic(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,1] * y_pred[:,:,:,1]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,1])) + K.sum(K.square(y_pred[:,:,:,1])) + epsilon)\n\ndef dice_coef_edema(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,2] * y_pred[:,:,:,2]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,2])) + K.sum(K.square(y_pred[:,:,:,2])) + epsilon)\n\ndef dice_coef_enhancing(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,3] * y_pred[:,:,:,3]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,3])) + K.sum(K.square(y_pred[:,:,:,3])) + epsilon)\n\ndef precision(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision\n\ndef sensitivity(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    return true_positives / (possible_positives + K.epsilon())\n\ndef specificity(y_true, y_pred):\n    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n    return true_negatives / (possible_negatives + K.epsilon())","metadata":{"execution":{"iopub.status.busy":"2022-09-10T06:20:17.733817Z","iopub.execute_input":"2022-09-10T06:20:17.734439Z","iopub.status.idle":"2022-09-10T06:20:17.757469Z","shell.execute_reply.started":"2022-09-10T06:20:17.734401Z","shell.execute_reply":"2022-09-10T06:20:17.756421Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"IMG_SIZE=128","metadata":{"execution":{"iopub.status.busy":"2022-09-10T06:20:17.759259Z","iopub.execute_input":"2022-09-10T06:20:17.759699Z","iopub.status.idle":"2022-09-10T06:20:17.776607Z","shell.execute_reply.started":"2022-09-10T06:20:17.759626Z","shell.execute_reply":"2022-09-10T06:20:17.775273Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"def build_unet(inputs, ker_init, dropout):\n    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(inputs)\n    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv1)\n    \n    pool = MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool)\n    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n    \n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool1)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv2)\n    \n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv3)\n    \n    \n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool4)\n    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv5)\n    drop5 = Dropout(dropout)(conv5)\n\n    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(drop5))\n    merge7 = concatenate([conv3,up7], axis = 3)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge7)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv7)\n\n    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv7))\n    merge8 = concatenate([conv2,up8], axis = 3)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge8)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv8)\n\n    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv8))\n    merge9 = concatenate([conv,up9], axis = 3)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge9)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv9)\n    \n    up = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv9))\n    merge = concatenate([conv1,up], axis = 3)\n    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge)\n    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n    \n    conv10 = Conv2D(4, (1,1), activation = 'softmax')(conv)\n    \n    return Model(inputs = inputs, outputs = conv10)\n\ninput_layer = Input((IMG_SIZE, IMG_SIZE, 2))\n\nmodel = build_unet(input_layer, 'he_normal', 0.2)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing] )","metadata":{"execution":{"iopub.status.busy":"2022-09-10T06:20:17.779465Z","iopub.execute_input":"2022-09-10T06:20:17.779791Z","iopub.status.idle":"2022-09-10T06:20:18.044342Z","shell.execute_reply.started":"2022-09-10T06:20:17.779750Z","shell.execute_reply":"2022-09-10T06:20:18.043274Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"plot_model(model, \n           show_shapes = True,\n           show_dtype=False,\n           show_layer_names = True, \n           rankdir = 'TB', \n           expand_nested = False, \n           dpi = 100)","metadata":{"execution":{"iopub.status.busy":"2022-09-10T06:20:18.045778Z","iopub.execute_input":"2022-09-10T06:20:18.046148Z","iopub.status.idle":"2022-09-10T06:20:18.785061Z","shell.execute_reply.started":"2022-09-10T06:20:18.046083Z","shell.execute_reply":"2022-09-10T06:20:18.784093Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"train_and_val_directories = [f.path for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]\n\ntrain_and_val_directories.remove(TRAIN_DATASET_PATH+'BraTS20_Training_355')\n\ndef pathListIntoIds(dirList):\n    x = []\n    for i in range(0,len(dirList)):\n        x.append(dirList[i][dirList[i].rfind('/')+1:])\n    return x\n\ntrain_and_test_ids = pathListIntoIds(train_and_val_directories); \n\n    \ntrain_test_ids, val_ids = train_test_split(train_and_test_ids,test_size=0.2) \ntrain_ids, test_ids = train_test_split(train_test_ids,test_size=0.15) ","metadata":{"execution":{"iopub.status.busy":"2022-09-10T06:20:18.790651Z","iopub.execute_input":"2022-09-10T06:20:18.791659Z","iopub.status.idle":"2022-09-10T06:20:18.807657Z","shell.execute_reply.started":"2022-09-10T06:20:18.791601Z","shell.execute_reply":"2022-09-10T06:20:18.806425Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"class DataGenerator(tf.keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = 1, n_channels = 2, shuffle=True):\n        'Initialization'\n        self.dim = dim\n        self.batch_size = batch_size\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        Batch_ids = [self.list_IDs[k] for k in indexes]\n\n        X, y = self.__data_generation(Batch_ids)\n\n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, Batch_ids):\n        'Generates data containing batch_size samples' \n        X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n        y = np.zeros((self.batch_size*VOLUME_SLICES, 240, 240))\n        Y = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, 4))\n\n        \n        for c, i in enumerate(Batch_ids):\n            case_path = os.path.join(TRAIN_DATASET_PATH, i)\n\n            data_path = os.path.join(case_path, f'{i}_flair.nii');\n            flair = nib.load(data_path).get_fdata()    \n\n            data_path = os.path.join(case_path, f'{i}_t1ce.nii');\n            ce = nib.load(data_path).get_fdata()\n            \n            data_path = os.path.join(case_path, f'{i}_seg.nii');\n            seg = nib.load(data_path).get_fdata()\n        \n            for j in range(VOLUME_SLICES):\n                 X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n                 X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n\n                 y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT];\n                    \n        y[y==4] = 3;\n        mask = tf.one_hot(y, 4);\n        Y = tf.image.resize(mask, (IMG_SIZE, IMG_SIZE));\n        return X/np.max(X), Y\n        \ntraining_generator = DataGenerator(train_ids)\nvalid_generator = DataGenerator(val_ids)\ntest_generator = DataGenerator(test_ids)","metadata":{"execution":{"iopub.status.busy":"2022-09-10T06:20:18.809742Z","iopub.execute_input":"2022-09-10T06:20:18.810515Z","iopub.status.idle":"2022-09-10T06:20:18.831691Z","shell.execute_reply.started":"2022-09-10T06:20:18.810474Z","shell.execute_reply":"2022-09-10T06:20:18.830272Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"def showDataLayout():\n    plt.bar([\"Train\",\"Valid\",\"Test\"],\n    [len(train_ids), len(val_ids), len(test_ids)], align='center',color=[ 'green','red', 'blue'])\n    plt.legend()\n\n    plt.ylabel('Number of images')\n    plt.title('Data distribution')\n\n    plt.show()\n    \nshowDataLayout()","metadata":{"execution":{"iopub.status.busy":"2022-09-10T06:20:18.833617Z","iopub.execute_input":"2022-09-10T06:20:18.834190Z","iopub.status.idle":"2022-09-10T06:20:19.063649Z","shell.execute_reply.started":"2022-09-10T06:20:18.834149Z","shell.execute_reply":"2022-09-10T06:20:19.062575Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"csv_logger = CSVLogger('training.log', separator=',', append=False)\n\n\ncallbacks = [\n      keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=2, min_lr=0.000001, verbose=1),\n        csv_logger\n    ]","metadata":{"execution":{"iopub.status.busy":"2022-09-10T06:20:19.065435Z","iopub.execute_input":"2022-09-10T06:20:19.065755Z","iopub.status.idle":"2022-09-10T06:20:19.073012Z","shell.execute_reply.started":"2022-09-10T06:20:19.065702Z","shell.execute_reply":"2022-09-10T06:20:19.070975Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"K.clear_session()\n\n# history =  model.fit(training_generator,\n#                     epochs=35,\n#                     steps_per_epoch=len(train_ids),\n#                     callbacks= callbacks,\n#                     validation_data = valid_generator\n#                     )  \n# model.save(\"model_x8O_dcs65.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-09-10T06:20:19.074732Z","iopub.execute_input":"2022-09-10T06:20:19.075069Z","iopub.status.idle":"2022-09-10T06:20:19.103460Z","shell.execute_reply.started":"2022-09-10T06:20:19.075010Z","shell.execute_reply":"2022-09-10T06:20:19.102498Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"model = keras.models.load_model('../input/modelperclasseval/model_per_class.h5', \n                                   custom_objects={ 'accuracy' : tf.keras.metrics.MeanIoU(num_classes=4),\n                                                   \"dice_coef\": dice_coef,\n                                                   \"precision\": precision,\n                                                   \"sensitivity\":sensitivity,\n                                                   \"specificity\":specificity,\n                                                   \"dice_coef_necrotic\": dice_coef_necrotic,\n                                                   \"dice_coef_edema\": dice_coef_edema,\n                                                   \"dice_coef_enhancing\": dice_coef_enhancing\n                                                  }, compile=False)\n\nhistory = pd.read_csv('../input/modelperclasseval/training_per_class.log', sep=',', engine='python')\n\nhist=history\n\nacc=hist['accuracy']\nval_acc=hist['val_accuracy']\n\nepoch=range(len(acc))\n\nloss=hist['loss']\nval_loss=hist['val_loss']\n\ntrain_dice=hist['dice_coef']\nval_dice=hist['val_dice_coef']\n\nf,ax=plt.subplots(1,4,figsize=(16,8))\n\nax[0].plot(epoch,acc,'b',label='Training Accuracy')\nax[0].plot(epoch,val_acc,'r',label='Validation Accuracy')\nax[0].legend()\n\nax[1].plot(epoch,loss,'b',label='Training Loss')\nax[1].plot(epoch,val_loss,'r',label='Validation Loss')\nax[1].legend()\n\nax[2].plot(epoch,train_dice,'b',label='Training dice coef')\nax[2].plot(epoch,val_dice,'r',label='Validation dice coef')\nax[2].legend()\n\nax[3].plot(epoch,hist['mean_io_u'],'b',label='Training mean IOU')\nax[3].plot(epoch,hist['val_mean_io_u'],'r',label='Validation mean IOU')\nax[3].legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-10T06:20:19.105832Z","iopub.execute_input":"2022-09-10T06:20:19.106134Z","iopub.status.idle":"2022-09-10T06:20:20.803966Z","shell.execute_reply.started":"2022-09-10T06:20:19.106106Z","shell.execute_reply":"2022-09-10T06:20:20.802956Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"def imageLoader(path):\n    image = nib.load(path).get_fdata()\n    X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n    for j in range(VOLUME_SLICES):\n        X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(image[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n        X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n\n        y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT];\n    return np.array(image)\n\n\ndef loadDataFromDir(path, list_of_files, mriType, n_images):\n    scans = []\n    masks = []\n    for i in list_of_files[:n_images]:\n        fullPath = glob.glob( i + '/*'+ mriType +'*')[0]\n        currentScanVolume = imageLoader(fullPath)\n        currentMaskVolume = imageLoader( glob.glob( i + '/*seg*')[0] ) \n        # for each slice in 3D volume, find also it's mask\n        for j in range(0, currentScanVolume.shape[2]):\n            scan_img = cv2.resize(currentScanVolume[:,:,j], dsize=(IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_AREA).astype('uint8')\n            mask_img = cv2.resize(currentMaskVolume[:,:,j], dsize=(IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_AREA).astype('uint8')\n            scans.append(scan_img[..., np.newaxis])\n            masks.append(mask_img[..., np.newaxis])\n    return np.array(scans, dtype='float32'), np.array(masks, dtype='float32')\n        \n","metadata":{"execution":{"iopub.status.busy":"2022-09-10T06:20:20.805966Z","iopub.execute_input":"2022-09-10T06:20:20.806599Z","iopub.status.idle":"2022-09-10T06:20:20.819370Z","shell.execute_reply.started":"2022-09-10T06:20:20.806552Z","shell.execute_reply":"2022-09-10T06:20:20.818367Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"def predictByPath(case_path,case):\n    files = next(os.walk(case_path))[2]\n    X = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE, 2))\n    \n    vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_flair.nii');\n    flair=nib.load(vol_path).get_fdata()\n    \n    vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_t1ce.nii');\n    ce=nib.load(vol_path).get_fdata() \n    \n    \n    for j in range(VOLUME_SLICES):\n        X[j,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n        X[j,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n        \n    return model.predict(X/np.max(X), verbose=1)\n\n\ndef showPredictsById(case, start_slice = 60):\n    path = f\"../input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_{case}\"\n    gt = nib.load(os.path.join(path, f'BraTS20_Training_{case}_seg.nii')).get_fdata()\n    origImage = nib.load(os.path.join(path, f'BraTS20_Training_{case}_flair.nii')).get_fdata()\n    p = predictByPath(path,case)\n\n    core = p[:,:,:,1]\n    edema= p[:,:,:,2]\n    enhancing = p[:,:,:,3]\n\n    plt.figure(figsize=(18, 50))\n    f, axarr = plt.subplots(1,6, figsize = (18, 50)) \n\n    for i in range(6): \n        axarr[i].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap=\"gray\", interpolation='none')\n    \n    axarr[0].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap=\"gray\")\n    axarr[0].title.set_text('Original image flair')\n    curr_gt=cv2.resize(gt[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_NEAREST)\n    axarr[1].imshow(curr_gt, cmap=\"Reds\", interpolation='none', alpha=0.3) # ,alpha=0.3,cmap='Reds'\n    axarr[1].title.set_text('Ground truth')\n    axarr[2].imshow(p[start_slice,:,:,1:4], cmap=\"Reds\", interpolation='none', alpha=0.3)\n    axarr[2].title.set_text('all classes')\n    axarr[3].imshow(edema[start_slice,:,:], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n    axarr[3].title.set_text(f'{SEGMENT_CLASSES[1]} predicted')\n    axarr[4].imshow(core[start_slice,:,], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n    axarr[4].title.set_text(f'{SEGMENT_CLASSES[2]} predicted')\n    axarr[5].imshow(enhancing[start_slice,:,], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n    axarr[5].title.set_text(f'{SEGMENT_CLASSES[3]} predicted')\n    plt.show()\n    \n    \nshowPredictsById(case=test_ids[0][-3:])\nshowPredictsById(case=test_ids[1][-3:])\nshowPredictsById(case=test_ids[2][-3:])\nshowPredictsById(case=test_ids[3][-3:])\nshowPredictsById(case=test_ids[4][-3:])\nshowPredictsById(case=test_ids[5][-3:])\nshowPredictsById(case=test_ids[6][-3:])\n\n\n# mask = np.zeros((10,10))\n# mask[3:-3, 3:-3] = 1 # white square in black background\n# im = mask + np.random.randn(10,10) * 0.01 # random image\n# masked = np.ma.masked_where(mask == 0, mask)\n\n# plt.figure()\n\n# plt.subplot(1,2,2)\n# plt.imshow(im, 'gray', interpolation='none')\n# plt.imshow(masked, 'jet', interpolation='none', alpha=0.7)\n\n# plt.subplot(1,2,1)\n# plt.imshow(im, 'gray', interpolation='none')\n\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-10T06:20:20.821084Z","iopub.execute_input":"2022-09-10T06:20:20.821995Z","iopub.status.idle":"2022-09-10T06:20:38.114265Z","shell.execute_reply.started":"2022-09-10T06:20:20.821949Z","shell.execute_reply":"2022-09-10T06:20:38.112987Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"case = case=test_ids[3][-3:]\npath = f\"../input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_{case}\"\ngt = nib.load(os.path.join(path, f'BraTS20_Training_{case}_seg.nii')).get_fdata()\np = predictByPath(path,case)\n\n\ncore = p[:,:,:,1]\nedema= p[:,:,:,2]\nenhancing = p[:,:,:,3]\n\ni=40 \neval_class = 2 \n\ngt[gt != eval_class] = 1 \n\nresized_gt = cv2.resize(gt[:,:,i+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))\n\nplt.figure()\nf, axarr = plt.subplots(1,2) \naxarr[0].imshow(resized_gt, cmap=\"gray\")\naxarr[0].title.set_text('ground truth')\naxarr[1].imshow(p[i,:,:,eval_class], cmap=\"gray\")\naxarr[1].title.set_text(f'predicted class: {SEGMENT_CLASSES[eval_class]}')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-10T06:20:38.116102Z","iopub.execute_input":"2022-09-10T06:20:38.117209Z","iopub.status.idle":"2022-09-10T06:20:38.857971Z","shell.execute_reply.started":"2022-09-10T06:20:38.117165Z","shell.execute_reply":"2022-09-10T06:20:38.856891Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema, dice_coef_enhancing] )\n# Evaluate the model on the test data using `evaluate`\nprint(\"Evaluate on test data\")\nresults = model.evaluate(test_generator, batch_size=100, callbacks= callbacks)\nprint(\"test loss, test acc:\", results)","metadata":{"execution":{"iopub.status.busy":"2022-09-10T06:20:38.860017Z","iopub.execute_input":"2022-09-10T06:20:38.860646Z","iopub.status.idle":"2022-09-10T06:20:42.773647Z","shell.execute_reply.started":"2022-09-10T06:20:38.860600Z","shell.execute_reply":"2022-09-10T06:20:42.772132Z"},"trusted":true},"execution_count":81,"outputs":[]}]}